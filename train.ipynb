{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brownwang0426/transformer-from-scratch/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhgpT8hhhhLd"
      },
      "source": [
        "# 手刻簡單的文字生成 transformer\n",
        "\n",
        "示範如何純粹用 pytorch 手刻一個簡單的文字生成 transformer \\\n",
        "並強化自己對於 transformer 的理解以及操作能力 \\\n",
        "如果有機會，未來會再增加 numpy 版本，並且使用 numpy 手刻 error back-propagation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZQm4saPhUYV"
      },
      "source": [
        "# For colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVZs5loNPbPn"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Brownwang0426/transformer-from-scratch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj-G_J3dPbPo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/transformer-from-scratch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdyb1d_hcml8"
      },
      "outputs": [],
      "source": [
        "!pip install torch dill datasets tqdm numpy IPython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZCN3-VOhY-M"
      },
      "source": [
        "# For local\n",
        "CUDA Toolkit 11.8 \\\n",
        "cuDNN 8.9.x \\\n",
        "pip install torch==2.0.1 --extra-index-url https://download.pytorch.org/whl/cu118  \n",
        "其餘套件可自行下載"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kEiLW6f-v2"
      },
      "source": [
        "# 導入官方套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mVWhBy17f-v3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "\n",
        "import csv\n",
        "\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "import gc\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import itertools\n",
        "\n",
        "import dill\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display, clear_output\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT-dGum0chjy"
      },
      "source": [
        "# 導入客製化套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MdLUtG5nchj0"
      },
      "outputs": [],
      "source": [
        "from model import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElhExcVoSxd7"
      },
      "source": [
        "# 確認有無讀取到 cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj5V_vlwSxd8"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    device_index = 0\n",
        "    device = torch.device(f\"cuda:{device_index}\")\n",
        "    print('using cuda...')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('using cpu...')\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ACgMI7chj6"
      },
      "source": [
        "# 參數區域"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q7t3r9iQVLrn"
      },
      "outputs": [],
      "source": [
        "# 其他可以用的有 squad  natural_questions\n",
        "source = \"daily_dialog\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmtYCrXKVLrn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 初始化 BERT tokenizer 和 vectorizer\n",
        "tokenizer  = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "vectorizer = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# 每個樣本要看多長的字\n",
        "max_length = 100\n",
        "\n",
        "# 進行每個 epoch 前要將多少 QA 轉換為 tensor\n",
        "fp_chunk_size = 20\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AcDtqnZ-chj7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 要進行幾回合\n",
        "num_epochs = 1\n",
        "\n",
        "# 訓練相關參數\n",
        "batch_size = 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JIWY3GRqchj8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 是否讀取之前訓練的模型\n",
        "retrain = True\n",
        "\n",
        "# 模型相關參數\n",
        "sequence_size = max_length\n",
        "feature_size = vectorizer.config.hidden_size\n",
        "output_size = tokenizer.vocab_size\n",
        "num_layers = 10\n",
        "num_heads = 4\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'softmax'\n",
        "initializer = \"xavier_normal\"\n",
        "optimizer = 'adam'\n",
        "loss = 'nl_loss'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.00001\n",
        "\n",
        "# 存檔區域\n",
        "model_directory = f'model.pth'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WxQLkClpepJM"
      },
      "outputs": [],
      "source": [
        "# 機器回覆你的時候，要用多少個字（當沒有結束標記出現的時候）\n",
        "response_length = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C7Lo0AWchj8"
      },
      "source": [
        "# 建立模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFBrvqtIchj9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 建立模型\n",
        "model = build_model(sequence_size,\n",
        "                    feature_size,\n",
        "                    output_size,\n",
        "                    num_layers,\n",
        "                    num_heads,\n",
        "                    hidden_activation,\n",
        "                    output_activation,\n",
        "                    initializer,\n",
        "                    optimizer,\n",
        "                    loss,\n",
        "                    bias,\n",
        "                    drop_rate,\n",
        "                    alpha)\n",
        "\n",
        "# 將模型放到 cuda\n",
        "model = model.to(device)\n",
        "\n",
        "# 讀取參數\n",
        "if retrain:\n",
        "    try:\n",
        "        model_dict = torch.load(model_directory)\n",
        "        model.load_state_dict(model_dict)\n",
        "        print('Model loaded.')\n",
        "    except:\n",
        "        print('Model not loaded. Now using new model.')\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total params: {total_params / 1e6:.2f} million\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDu9hgebchj9"
      },
      "source": [
        "# 準備資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Pjoc3YSYchj-"
      },
      "outputs": [],
      "source": [
        "# 定義 function\n",
        "def create_dataset(input_vectors, input_ids, output_size, attention_masks):\n",
        "\n",
        "    final_input  = []\n",
        "    final_label  = []\n",
        "    final_mask_1 = []\n",
        "    final_mask_2 = []\n",
        "\n",
        "    for i in range(input_vectors.size(0)):\n",
        "        for j in range(input_vectors.size(1) - 1):\n",
        "\n",
        "            if attention_masks[i][j + 1] != 0:\n",
        "\n",
        "                factored_mask       = torch.zeros_like(attention_masks[i])\n",
        "                factored_mask[:j+1] = 1\n",
        "                input               = input_vectors[i] * factored_mask.unsqueeze(1)\n",
        "                final_input.append(input)\n",
        "\n",
        "                label = input_ids[i][j + 1]\n",
        "                final_label.append(label)\n",
        "\n",
        "                mask_2 = factored_mask.unsqueeze(1) * factored_mask.unsqueeze(0)\n",
        "                mask_2 = mask_2.unsqueeze(0)\n",
        "                mask_1 = (mask_2 -1) * 1e20\n",
        "                final_mask_1.append(mask_1)\n",
        "                final_mask_2.append(mask_2)\n",
        "\n",
        "    final_input  = torch.stack(final_input , dim=0)\n",
        "    final_label  = torch.tensor(final_label, dtype=torch.long)\n",
        "    final_mask_1 = torch.stack(final_mask_1, dim=0)\n",
        "    final_mask_2 = torch.stack(final_mask_2, dim=0)\n",
        "\n",
        "    return final_input, final_label, final_mask_1, final_mask_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 讀取資料\n",
        "dataset     = load_dataset(source, trust_remote_code=True )\n",
        "\n",
        "# 抽取資料\n",
        "questions = []\n",
        "answers   = []\n",
        "# Process each dialogue\n",
        "for dialog in dataset['train']['dialog']:\n",
        "    # Separate utterances into Person A and Person B\n",
        "    person_a_utterances = dialog[::2]   # Odd-indexed utterances are Person A's\n",
        "    person_b_utterances = dialog[1::2]  # Even-indexed utterances are Person B's\n",
        "    person_max_length = max(len(person_a_utterances), len(person_b_utterances))\n",
        "    if len(person_a_utterances) < person_max_length:\n",
        "        person_b_utterances = person_b_utterances[:-1]\n",
        "    if len(person_b_utterances) < person_max_length:\n",
        "        person_a_utterances = person_a_utterances[:-1]\n",
        "    # Join Person A's and Person B's utterances into strings\n",
        "    questions.extend(person_a_utterances)\n",
        "    answers.extend(person_b_utterances)\n",
        "\n",
        "# 建立 QA\n",
        "qa_pairs  = []\n",
        "for q, a in zip(questions, answers):\n",
        "    qa_pairs.append(f\"[CLS] {q} [SEP] {a} [SEP] \")\n",
        "sentences = qa_pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0chhWYKWchj-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(sys.maxsize):\n",
        "\n",
        "    # 隨機排序\n",
        "    random.shuffle(sentences)\n",
        "\n",
        "    # 隨機取 QA 起始值\n",
        "    j = np.random.randint( int(len(sentences)/fp_chunk_size) )\n",
        "\n",
        "    # 將 QA tokenize\n",
        "    tokenized_sentences = tokenizer(sentences[ j*fp_chunk_size : j*fp_chunk_size+fp_chunk_size ], \n",
        "                                    add_special_tokens=False, \n",
        "                                    padding='max_length', \n",
        "                                    max_length=max_length, \n",
        "                                    truncation=True, \n",
        "                                    return_tensors=\"pt\")\n",
        "\n",
        "    # 將 QA vectorize\n",
        "    input_ids           = tokenized_sentences['input_ids']\n",
        "    attention_masks     = tokenized_sentences['attention_mask']\n",
        "    with torch.no_grad():\n",
        "        input_vectors   = vectorizer(input_ids).last_hidden_state * ( attention_masks.unsqueeze(2) )\n",
        "\n",
        "    # 生成 tensor 訓練集，並且開始批次儲存 tensor\n",
        "    final_input, final_label, final_mask_1, final_mask_2 = create_dataset(input_vectors, input_ids, output_size, attention_masks)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 開始抽取資料\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # 彙整 QA 訓練集\n",
        "        dataset         = TensorDataset(final_input, final_label, final_mask_1, final_mask_2)\n",
        "        dataloader      = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # 訓練模型\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (input, label, mask_1, mask_2) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training Progress\", ncols=100, unit=\"batch\"):\n",
        "\n",
        "            input  = input.to(device)\n",
        "            label  = label.to(device)\n",
        "            mask_1 = mask_1.to(device)\n",
        "            mask_2 = mask_2.to(device)\n",
        "\n",
        "            optimizer = model.optimizer\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_function   = model.loss_function\n",
        "            output          = model(input, (mask_1, mask_2))\n",
        "            loss            = loss_function(output, label)\n",
        "            loss.backward()     # get grad\n",
        "\n",
        "            optimizer.step()    # update params\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] finished. Average Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        model_dict = model.state_dict()\n",
        "        torch.save(model_dict, model_directory)\n",
        "        \n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TpHHO3UevbY"
      },
      "source": [
        "# 來跟這個小模型用英文聊聊天吧"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "M85l53w3chkD"
      },
      "outputs": [],
      "source": [
        "# 你要問的句子\n",
        "sentence = \" Do you like me?        \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6PUPm6AchkD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 幫你的問題補上 [CSL] 以及 [SEP] ，讓機器可以知道問句的開始與結束\n",
        "sentence = \"[CLS] \" + sentence + \" [SEP] \"\n",
        "\n",
        "# 機器的回答\n",
        "response = ''\n",
        "\n",
        "# 開始遞迴\n",
        "for i in range(response_length):\n",
        "\n",
        "    # 將 QA tokenize\n",
        "    tokenized_sentence = tokenizer(sentence, add_special_tokens=False, padding='max_length', max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # 將 QA vectorize\n",
        "    input_id           = tokenized_sentence['input_ids']\n",
        "    attention_mask     = tokenized_sentence['attention_mask']\n",
        "    with torch.no_grad():\n",
        "        input_vector   = vectorizer(input_id).last_hidden_state * ( attention_mask.unsqueeze(2) )\n",
        "    input_vector = input_vector.to(device)\n",
        "\n",
        "    # 製作對應 QA 長度的 mask\n",
        "    mask_2 = attention_mask[0].unsqueeze(1) * attention_mask[0].unsqueeze(0)\n",
        "    mask_2 = mask_2.unsqueeze(0).unsqueeze(0)\n",
        "    mask_2 = mask_2.to(device)\n",
        "    mask_1 = (mask_2 -1) * 1e20\n",
        "    mask_1 = mask_1.to(device)\n",
        "\n",
        "    # 將你的問題向量丟到模型去吧\n",
        "    model.eval()\n",
        "    output                  = model(input_vector, (mask_1, mask_2))\n",
        "\n",
        "    # 選擇最高概率的詞\n",
        "    most_probable_token_idx = torch.argmax(output, dim=-1).item()\n",
        "    word = tokenizer.convert_ids_to_tokens(most_probable_token_idx)\n",
        "\n",
        "    # 將機器人吐出的那個字拼接回去\n",
        "    if word not in ['[SEP]']:\n",
        "        sentence += ' ' + word\n",
        "        response += ' ' + word\n",
        "        clear_output(wait=True)  # Clear the previous output\n",
        "        print(response, flush=False)\n",
        "        display()  # Display the updated output\n",
        "    else:\n",
        "        print(\"[END]\")\n",
        "        break\n",
        "\n",
        "    # 將機器人吐出的那個字拼接回去\n",
        "    # while word in ['[SEP]', '.', ',', '?']:\n",
        "    #     output[0][most_probable_token_idx] = -1000000000\n",
        "    #     most_probable_token_idx = torch.argmax(output, dim=-1).item()\n",
        "    #     word = tokenizer.convert_ids_to_tokens(most_probable_token_idx)\n",
        "    # sentence += ' ' + word\n",
        "    # response += ' ' + word\n",
        "    # clear_output(wait=True)  # Clear the previous output\n",
        "    # print(response, flush=False)\n",
        "    # display()  # Display the updated output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0krnWZyBchkE"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# model_save_path = '/content/drive/My Drive/model.pth'\n",
        "# torch.save(model.state_dict(), model_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iwR5cGQVLrq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
