{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brownwang0426/transformer-from-scratch/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhgpT8hhhhLd"
      },
      "source": [
        "# 手刻簡單的文字生成 transformer\n",
        "\n",
        "示範如何純粹用 pytorch 手刻一個簡單的文字生成 transformer \\\n",
        "並強化自己對於 transformer 的理解以及操作能力 \\\n",
        "如果有機會，未來會再增加 numpy 版本，並且使用 numpy 手刻 error back-propagation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZQm4saPhUYV"
      },
      "source": [
        "# For colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVZs5loNPbPn",
        "outputId": "d115b769-b98a-49fc-f16e-fd886c853c34"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Brownwang0426/transformer-from-scratch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hj-G_J3dPbPo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/transformer-from-scratch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdyb1d_hcml8",
        "outputId": "bca3485c-7207-4890-916f-094f8a36d10d"
      },
      "outputs": [],
      "source": [
        "!pip install torch dill datasets tqdm numpy IPython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZCN3-VOhY-M"
      },
      "source": [
        "# For local\n",
        "CUDA Toolkit 11.8 \\\n",
        "cuDNN 8.9.x \\\n",
        "pip install torch==2.0.1 --extra-index-url https://download.pytorch.org/whl/cu118  \n",
        "其餘套件可自行下載"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kEiLW6f-v2"
      },
      "source": [
        "# 導入官方套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mVWhBy17f-v3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "\n",
        "import csv\n",
        "\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "import gc\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import itertools\n",
        "\n",
        "import dill\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT-dGum0chjy"
      },
      "source": [
        "# 導入客製化套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MdLUtG5nchj0"
      },
      "outputs": [],
      "source": [
        "from model import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElhExcVoSxd7"
      },
      "source": [
        "# 確認有無讀取到 cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj5V_vlwSxd8",
        "outputId": "33420cda-1a59-404d-c257-5358e4e2af7a"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    device_index = 0\n",
        "    device = torch.device(f\"cuda:{device_index}\")\n",
        "    print('using cuda...')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('using cpu...')\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ACgMI7chj6"
      },
      "source": [
        "# 參數區域"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 初始化 BERT tokenizer 和 vectorizer\n",
        "tokenizer  = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "vectorizer = AutoModel.from_pretrained(\"roberta-base\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AcDtqnZ-chj7"
      },
      "outputs": [],
      "source": [
        "# 其他可以用的有 squad  natural_questions\n",
        "source = \"daily_dialog\" \n",
        "\n",
        "# 是否讀取之前訓練的模型\n",
        "retrain = True     \n",
        "\n",
        "# 要進行幾回合\n",
        "interval   = 1000000 \n",
        "\n",
        "# 每一回合要抽取多少樣本\n",
        "train_size = 50          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JIWY3GRqchj8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 每個樣本要看多長的字\n",
        "max_length = 200\n",
        "\n",
        "sequence_size = max_length\n",
        "feature_size = vectorizer.config.hidden_size\n",
        "output_size = tokenizer.vocab_size\n",
        "num_layers = 3\n",
        "num_heads = 4\n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'softmax'\n",
        "initializer = \"xavier_normal\"\n",
        "optimizer = 'adam'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.0000001\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 1\n",
        "\n",
        "model_directory = f'model.pth'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WxQLkClpepJM"
      },
      "outputs": [],
      "source": [
        "\n",
        "response_length = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C7Lo0AWchj8"
      },
      "source": [
        "# 建立模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFBrvqtIchj9",
        "outputId": "65040642-61bd-4065-dde2-7b2843641d32"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 建立模型\n",
        "model = build_model(sequence_size,\n",
        "                    feature_size,\n",
        "                    output_size,\n",
        "                    num_layers,\n",
        "                    num_heads,\n",
        "                    hidden_activation,\n",
        "                    output_activation,\n",
        "                    initializer,\n",
        "                    optimizer,\n",
        "                    loss,\n",
        "                    bias,\n",
        "                    drop_rate,\n",
        "                    alpha)\n",
        "\n",
        "# 將模型放到 cuda\n",
        "model = model.to(device)\n",
        "\n",
        "# 讀取參數\n",
        "if retrain:\n",
        "    try:\n",
        "        model_dict = torch.load(model_directory)\n",
        "        model.load_state_dict(model_dict[f'model'])\n",
        "        print('Model loaded.')\n",
        "    except:\n",
        "        print('Model not loaded. Now using new model.')\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDu9hgebchj9"
      },
      "source": [
        "# 準備資料並訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Pjoc3YSYchj-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(input_vectors, input_ids, output_size, attention_masks):\n",
        "\n",
        "    final_input  = []\n",
        "    final_label  = []\n",
        "    final_mask_1 = []\n",
        "    final_mask_2 = []\n",
        "\n",
        "    for i in tqdm(range(input_vectors.size(0))):\n",
        "        for j in range(input_vectors.size(1) - 1):\n",
        "\n",
        "            if attention_masks[i][j + 1] != 0:\n",
        "\n",
        "                factored_mask       = torch.zeros_like(attention_masks[i])\n",
        "                factored_mask[:j+1] = 1\n",
        "                input               = input_vectors[i] * factored_mask.unsqueeze(1)\n",
        "                final_input.append(input)\n",
        "\n",
        "                label = torch.zeros(output_size)\n",
        "                label[input_ids[i][j+1]] = 1\n",
        "                final_label.append(label)\n",
        "\n",
        "                mask_2 = factored_mask.unsqueeze(1) * factored_mask.unsqueeze(0)\n",
        "                mask_2 = mask_2.unsqueeze(0)\n",
        "                mask_1 = (mask_2 -1) * 1e20\n",
        "                final_mask_1.append(mask_1)\n",
        "                final_mask_2.append(mask_2)\n",
        "\n",
        "    final_input  = torch.stack(final_input , dim=0)\n",
        "    final_label  = torch.stack(final_label , dim=0)\n",
        "    final_mask_1 = torch.stack(final_mask_1, dim=0)\n",
        "    final_mask_2 = torch.stack(final_mask_2, dim=0)\n",
        "\n",
        "    return final_input, final_label, final_mask_1, final_mask_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 讀取資料\n",
        "dataset     = load_dataset(source, trust_remote_code=True )\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "# Process each dialogue\n",
        "for dialog in dataset['train']['dialog']:\n",
        "    # Separate utterances into Person A and Person B\n",
        "    person_a_utterances = dialog[::2]  # Odd-indexed utterances are Person A's\n",
        "    person_b_utterances = dialog[1::2]  # Even-indexed utterances are Person B's\n",
        "\n",
        "    person_max_length = max(len(person_a_utterances), len(person_b_utterances))\n",
        "    while len(person_a_utterances) < person_max_length:\n",
        "        person_a_utterances.append(\"[SEP]\")  # Add empty string or \"[No Response]\"\n",
        "    while len(person_b_utterances) < person_max_length:\n",
        "        person_b_utterances.append(\"[SEP]\")  # Add empty string or \"[No Response]\"\n",
        "\n",
        "    # Join Person A's and Person B's utterances into strings\n",
        "    questions.extend(person_a_utterances)\n",
        "    answers.extend(person_b_utterances)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "0chhWYKWchj-",
        "outputId": "a14cc8bd-d248-4ede-aa5e-12dd54ec4f42"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 確定要抽取的 QA 大小\n",
        "train_size  = min(train_size, len(questions))\n",
        "\n",
        "# 開始抽取資料\n",
        "for _ in range(interval):\n",
        "\n",
        "    # 隨機 indices\n",
        "    random_indices = random.sample(range(len(questions)), train_size)\n",
        "\n",
        "    # 抽取 QA\n",
        "    questions = [questions[i] for i in random_indices]\n",
        "    answers   = [answers[i]   for i in random_indices]\n",
        "\n",
        "    # 建立 QA\n",
        "    qa_pairs  = []\n",
        "    for question, answer in zip(questions, answers):\n",
        "        qa_pairs.append(f\"[CLS] {question} [SEP] {answer} [SEP] \")\n",
        "\n",
        "    # 偷看一下 QA 裡面有什麼東西\n",
        "    for qa in qa_pairs[:3]:\n",
        "        print(qa)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # 改一下名稱\n",
        "    sentences = qa_pairs\n",
        "\n",
        "    # 將 QA tokenize\n",
        "    tokenized_sentences = tokenizer(sentences, add_special_tokens=False, padding='max_length', max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # 將 QA vectorize\n",
        "    input_ids           = tokenized_sentences['input_ids']\n",
        "    attention_masks     = tokenized_sentences['attention_mask']\n",
        "    with torch.no_grad():\n",
        "        input_vectors   = vectorizer(input_ids).last_hidden_state * ( attention_masks.unsqueeze(2) )\n",
        "\n",
        "    # 生成 QA 訓練集\n",
        "    final_input, final_label, final_mask_1, final_mask_2 = create_dataset(input_vectors, input_ids, output_size, attention_masks)\n",
        "\n",
        "    # 彙整 QA 訓練集\n",
        "    dataset    = TensorDataset(final_input, final_label, final_mask_1, final_mask_2)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # 訓練模型\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (input, label, mask_1, mask_2) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training Progress\", ncols=100, unit=\"batch\"):\n",
        "\n",
        "            input  = input.to(device)\n",
        "            label  = label.to(device)\n",
        "            mask_1 = mask_1.to(device)\n",
        "            mask_2 = mask_2.to(device)\n",
        "\n",
        "            optimizer = model.optimizer\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_function   = model.loss_function\n",
        "            output          = model(input, (mask_1, mask_2))\n",
        "            loss            = loss_function(output, label)\n",
        "            loss.backward()     # get grad\n",
        "\n",
        "            optimizer.step()    # update params\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] finished. Average Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        model_dict = {}\n",
        "        model_dict[f'model'] = model.state_dict()\n",
        "        torch.save(model_dict, model_directory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TpHHO3UevbY"
      },
      "source": [
        "# 來跟這個小模型用英文聊聊天吧"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "M85l53w3chkD"
      },
      "outputs": [],
      "source": [
        "# 你要問的句子\n",
        "sentence = \"Please talk like human, dummy!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "L6PUPm6AchkD",
        "outputId": "7b5311f6-94dd-4a16-9478-9df2fe2ef6ad"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 幫你的問題補上 [CSL] 以及 [SEP] ，讓機器可以知道問句的開始與結束\n",
        "sentence = \"[CLS] \" + sentence + \" [SEP] \"\n",
        "\n",
        "# 機器的回答\n",
        "response = ''\n",
        "\n",
        "# 開始遞迴\n",
        "for i in range(response_length):\n",
        "\n",
        "    # 將 QA tokenize\n",
        "    tokenized_sentence = tokenizer(sentence, add_special_tokens=False, padding='max_length', max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # 將 QA vectorize\n",
        "    input_id           = tokenized_sentence['input_ids']\n",
        "    attention_mask     = tokenized_sentence['attention_mask']\n",
        "    with torch.no_grad():\n",
        "        input_vector   = vectorizer(input_id).last_hidden_state * ( attention_mask.unsqueeze(2) )\n",
        "    input_vector = input_vector.to(device)\n",
        "\n",
        "    # 製作對應 QA 長度的 mask\n",
        "    mask_2 = attention_mask[0].unsqueeze(1) * attention_mask[0].unsqueeze(0)\n",
        "    mask_2 = mask_2.unsqueeze(0).unsqueeze(0)\n",
        "    mask_2 = mask_2.to(device)\n",
        "    mask_1 = (mask_2 -1) * 1e20\n",
        "    mask_1 = mask_1.to(device)\n",
        "\n",
        "    # 將你的問題向量丟到模型去吧\n",
        "    model.eval()\n",
        "    output                  = model(input_vector, (mask_1, mask_2))\n",
        "\n",
        "    # 選擇最高概率的詞\n",
        "    most_probable_token_idx = torch.argmax(output, dim=-1).item()\n",
        "\n",
        "    # 將機器人吐出的那個字拼接回去\n",
        "    if most_probable_token_idx != 102:\n",
        "        word = tokenizer.convert_ids_to_tokens(most_probable_token_idx)\n",
        "        sentence += ' ' + word\n",
        "        response += ' ' + word\n",
        "        clear_output(wait=True)  # Clear the previous output\n",
        "        print(response, flush=False)\n",
        "        display()  # Display the updated output\n",
        "    else:\n",
        "        print(\"[END]\")\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSRFJhMCchkE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0krnWZyBchkE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fAercPIchkE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Genrl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
