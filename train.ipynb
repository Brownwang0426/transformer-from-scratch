{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brownwang0426/transformer-from-scratch/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 手刻簡單的文字生成 transformer\n",
        "## 1. 目的\n",
        "示範如何純粹用 pytorch 手刻一個簡單的文字生成 transformer \\\n",
        "並強化自己對於 transformer 的理解以及操作能力\n",
        "## 2.未來\n",
        "如果有機會，未來會再增加 numpy 版本，並且使用 numpy 手刻 error back-propagation\n",
        "## 3. 套件\n",
        "(for local) \\\n",
        "CUDA Toolkit 11.8 \\\n",
        "cuDNN 8.9.x \\\n",
        "pip install torch==2.0.1 --extra-index-url https://download.pytorch.org/whl/cu118  \n",
        "其餘套件可自行下載"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6kEiLW6f-v2"
      },
      "source": [
        "# 導入官方套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mVWhBy17f-v3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "\n",
        "import csv\n",
        "\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "import gc\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import itertools\n",
        "\n",
        "import dill\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 導入客製化套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElhExcVoSxd7"
      },
      "source": [
        "# 確認有無讀取到 cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Aj5V_vlwSxd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device 0: NVIDIA GeForce RTX 4090\n",
            "using cuda...\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    device_index = 0\n",
        "    device = torch.device(f\"cuda:{device_index}\")\n",
        "    print('using cuda...')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('using cpu...')\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 參數區域"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "source = \"natural_questions\" # 其他可以用的有 squad  natural_questions\n",
        "\n",
        "retrain = True\n",
        "\n",
        "interval   = 1000000\n",
        "train_size = 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "max_length = 200\n",
        "\n",
        "sequence_size =  max_length             \n",
        "feature_size = 768          \n",
        "num_layers = 3                      \n",
        "num_heads = 4                \n",
        "hidden_activation = 'tanh'\n",
        "output_activation = 'tanh'\n",
        "initializer = \"xavier_normal\"\n",
        "optimizer = 'adam'\n",
        "loss = 'mean_squared_error'\n",
        "bias = False\n",
        "drop_rate = 0.0\n",
        "alpha = 0.0000001       \n",
        "\n",
        "num_epochs = 100  \n",
        "batch_size = 1\n",
        "\n",
        "model_directory = f'model.pth'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 建立模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 建立模型\n",
        "model = build_model(sequence_size,\n",
        "                    feature_size,\n",
        "                    num_layers,\n",
        "                    num_heads,\n",
        "                    hidden_activation,\n",
        "                    output_activation,\n",
        "                    initializer,\n",
        "                    optimizer,\n",
        "                    loss,\n",
        "                    bias,\n",
        "                    drop_rate,\n",
        "                    alpha)\n",
        "\n",
        "# 將模型放到 cuda\n",
        "model = model.to(device)\n",
        "\n",
        "# 讀取參數\n",
        "if retrain:\n",
        "    model_dict = torch.load(model_directory)\n",
        "    model.load_state_dict(model_dict[f'model'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 準備資料並訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataset(input_vectors, attention_masks):\n",
        "\n",
        "    final_input  = []\n",
        "    final_label  = []\n",
        "    final_mask_1 = []\n",
        "    final_mask_2 = []\n",
        "\n",
        "    for i in tqdm(range(input_vectors.size(0))): \n",
        "        for j in range(input_vectors.size(1) - 1):\n",
        "            \n",
        "            if attention_masks[i][j + 1] != 0:\n",
        "\n",
        "                factored_mask       = torch.zeros_like(attention_masks[i])\n",
        "                factored_mask[:j+1] = 1\n",
        "                input               = input_vectors[i] * factored_mask.unsqueeze(1)\n",
        "                final_input.append(input)\n",
        "\n",
        "                label = input_vectors[i][j+1]\n",
        "                final_label.append(label)\n",
        "\n",
        "                mask_2 = factored_mask.unsqueeze(1) * factored_mask.unsqueeze(0)\n",
        "                mask_2 = mask_2.unsqueeze(0)\n",
        "                mask_1 = (mask_2 -1) * 1e20\n",
        "                final_mask_1.append(mask_1)\n",
        "                final_mask_2.append(mask_2)\n",
        "\n",
        "    final_input  = torch.stack(final_input , dim=0)\n",
        "    final_label  = torch.stack(final_label , dim=0)\n",
        "    final_mask_1 = torch.stack(final_mask_1, dim=0)\n",
        "    final_mask_2 = torch.stack(final_mask_2, dim=0)\n",
        "\n",
        "    return final_input, final_label, final_mask_1, final_mask_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading data:  89%|████████▉ | 255/287 [48:35<32:15, 60.49s/files]"
          ]
        }
      ],
      "source": [
        "# 讀取資料\n",
        "dataset     = load_dataset(source, trust_remote_code=True )\n",
        "questions   = dataset['train']['question']\n",
        "answers     = dataset['train']['answers' ]\n",
        "\n",
        "# 確定要抽取的 QA 大小\n",
        "train_size  = min(train_size, len(questions))\n",
        "\n",
        "# 開始抽取資料\n",
        "for _ in range(interval):\n",
        "\n",
        "    # 隨機 indices\n",
        "    random_indices = random.sample(range(len(questions)), train_size)\n",
        "\n",
        "    # 抽取 QA\n",
        "    questions = [questions[i] for i in random_indices]\n",
        "    answers   = [answers[i]   for i in random_indices]\n",
        "\n",
        "    # 建立 QA \n",
        "    qa_pairs  = []\n",
        "    for question, answer in zip(questions, answers):\n",
        "        qa_pairs.append(f\"[CLS] {question} [SEP] {answer['text'][0]} [SEP] \")\n",
        "\n",
        "    # 偷看一下 QA 裡面有什麼東西\n",
        "    for qa in qa_pairs[:3]:\n",
        "        print(qa)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # 初始化 BERT tokenizer 和 vectorizer\n",
        "    tokenizer  = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    vectorizer = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # 改一下名稱\n",
        "    sentences = qa_pairs\n",
        "\n",
        "    # 將 QA tokenize\n",
        "    tokenized_sentences = tokenizer(sentences, add_special_tokens=False, padding='max_length', max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # 將 QA vectorize\n",
        "    input_ids           = tokenized_sentences['input_ids']\n",
        "    attention_masks     = tokenized_sentences['attention_mask']\n",
        "    with torch.no_grad(): \n",
        "        input_vectors   = vectorizer(input_ids).last_hidden_state * ( attention_masks.unsqueeze(2) )\n",
        "\n",
        "    # 生成 QA 訓練集\n",
        "    final_input, final_label, final_mask_1, final_mask_2 = create_dataset(input_vectors, attention_masks)\n",
        "\n",
        "    # 彙整 QA 訓練集\n",
        "    dataset    = TensorDataset(final_input, final_label, final_mask_1, final_mask_2)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # 訓練模型\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        model.train()  \n",
        "        \n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (input, label, mask_1, mask_2) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training Progress\", ncols=100, unit=\"batch\"):\n",
        "\n",
        "            input  = input.to(device)\n",
        "            label  = label.to(device)\n",
        "            mask_1 = mask_1.to(device)\n",
        "            mask_2 = mask_2.to(device)\n",
        "            \n",
        "            optimizer = model.optimizer\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_function   = model.loss_function\n",
        "            output          = model(input, (mask_1, mask_2))\n",
        "            loss            = loss_function(output, label)\n",
        "            loss.backward()     # get grad\n",
        "            \n",
        "            optimizer.step()    # update params \n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] finished. Average Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        model_dict = {}\n",
        "        model_dict[f'model'] = model.state_dict()\n",
        "        torch.save(model_dict, model_directory)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model_dict = {}\n",
        "model_dict[f'model'] = model.state_dict()\n",
        "torch.save(model_dict, model_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKTJbMhmZvVI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
